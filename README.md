# HDFS Project
Utilizing both MapReduce and Spark tech to parse and analyze huge size files on an internal file system.  
## task1 - MapReduce
1. WordCount: Count the number of occurence of each word in a file.  
2. WordCounter: Count the total number of words in a file.  
3. Randr: Count the number of words that contain "rr".  
4. RRandNotRR: Count the number of words that contain "rr" and the number of words that do not contain "rr".  
5. MaxTemperature: Calculate the max temperature of Pittsburgh in a long period.  
6. MaxTemperature and MinTemperature: Calculate the max temperature and min temperature of Pittsburgh in a long period.  
7. RapesPlusRobberies: Calculate the total occurance of rapes and robberies in Pittsburgh in 1990.  
8. AssaultInOakland: Calculate the total occurance of assaults in Oakland, Pittsburgh in 1990.  
9. OaklandCrimeStatsKML: Calculate the total occurance of assaults in Oakland, Pittsburgh in 1990 and display them as point of interest in Google Earth.
## task2 - Spark
Analyzing a .txt file to perform the following functionalities:  
1. Find the number of lines  
2. Find the number of words  
3. Find the number of distinct words  
4. Find the number of each word in 2 different part of the file  
5. Ask user to type words to search and return the user the lines containing the search words.
